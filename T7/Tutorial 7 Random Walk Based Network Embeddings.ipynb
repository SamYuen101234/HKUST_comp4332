{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load networks into memory. Usually networks are organized as pairs of nodes. And sometimes different edges have different weights. Hence, we use networkx.DiGraph to store such structure information and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    \"\"\"\n",
    "    read edges from an edge file\n",
    "    \"\"\"\n",
    "    edges = list()\n",
    "    df = pd.read_csv(file_name)\n",
    "    for idx, row in df.iterrows():\n",
    "        user_id, friends = row[\"user_id\"], eval(row[\"friends\"])\n",
    "        for friend in friends:\n",
    "            # add each friend relation as an edge\n",
    "            ########## begin ##########\n",
    "            edges.append((user_id, friend))\n",
    "            ########## end ##########\n",
    "    edges = sorted(edges)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def generate_false_edges(true_edges, num_false_edges=5):\n",
    "    \"\"\"\n",
    "    generate false edges given true edges\n",
    "    \"\"\"\n",
    "    nodes = list(set(chain.from_iterable(true_edges)))\n",
    "    true_edges = set(true_edges)\n",
    "    false_edges = set()\n",
    "    while len(false_edges) < num_false_edges:\n",
    "        # randomly sample two different nodes and check whether the pair exisit or not\n",
    "        ########## begin ##########\n",
    "        head, tail = np.random.choice(nodes, 2)\n",
    "        if head != tail and (head, tail) not in true_edges and (head, tail) not in false_edges:\n",
    "            false_edges.add((head, tail))\n",
    "        ########## end ##########\n",
    "\n",
    "    false_edges = sorted(false_edges)    \n",
    "    return false_edges\n",
    "\n",
    "def construct_graph_from_edges(edges):\n",
    "    \"\"\"\n",
    "    generate a directed graph object given true edges\n",
    "    DiGraph documentation: https://networkx.github.io/documentation/stable/reference/classes/digraph.html\n",
    "    \"\"\"\n",
    "    # convert a list of edges {(u, v)} to a list of edges with weights {(u, v, w)}\n",
    "    edge_weight = defaultdict(float)\n",
    "    for e in edges:\n",
    "        edge_weight[e] += 1.0\n",
    "    weighed_edge_list = list()\n",
    "    for e in sorted(edge_weight.keys()):\n",
    "        weighed_edge_list.append((e[0], e[1], edge_weight[e]))\n",
    "        \n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_weighted_edges_from(weighed_edge_list)\n",
    "    \n",
    "    print(\"number of nodes:\", graph.number_of_nodes())\n",
    "    print(\"number of edges:\", graph.number_of_edges())\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to load edges into memory and use the networkx.DiGraph structure to store the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 3930\n",
      "number of edges: 15688\n"
     ]
    }
   ],
   "source": [
    "user_file = \"data/user.csv\"\n",
    "edges = load_data(user_file)\n",
    "graph = construct_graph_from_edges(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random walk generators or random walkers yield random walks that contain both local and higher-order neighborhood information. However, naive non-uniform sampling is very slow, which requires O(n) time complexity. Here alias sampling can reduce the time complexity to O(1) with O(n) space. If you are interested, please see the following blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alias_setup(probs):\n",
    "    \"\"\"\n",
    "    compute utility lists for non-uniform sampling from discrete distributions.\n",
    "    details: https://lips.cs.princeton.edu/the-alias-method-efficient-sampling-with-many-discrete-outcomes/\n",
    "    \"\"\"\n",
    "    K = len(probs)\n",
    "    q = np.zeros(K)\n",
    "    J = np.zeros(K, dtype=np.int)\n",
    "\n",
    "    smaller = list()\n",
    "    larger = list()\n",
    "    for kk, prob in enumerate(probs):\n",
    "        q[kk] = K * prob\n",
    "        if q[kk] < 1.0:\n",
    "            smaller.append(kk)\n",
    "        else:\n",
    "            larger.append(kk)\n",
    "\n",
    "    while len(smaller) > 0 and len(larger) > 0:\n",
    "        small = smaller.pop()\n",
    "        large = larger.pop()\n",
    "\n",
    "        J[small] = large\n",
    "        q[large] = q[large] + q[small] - 1.0\n",
    "        if q[large] < 1.0:\n",
    "            smaller.append(large)\n",
    "        else:\n",
    "            larger.append(large)\n",
    "\n",
    "    return J, q\n",
    "\n",
    "def get_alias_node(graph, node):\n",
    "    \"\"\"\n",
    "    get the alias node setup lists for a given node.\n",
    "    \"\"\"\n",
    "    # get the unnormalized probabilities with the first-order information\n",
    "    unnormalized_probs = list()\n",
    "    for nbr in graph.neighbors(node):\n",
    "        unnormalized_probs.append(graph[node][nbr]['weight'])\n",
    "    unnormalized_probs = np.array(unnormalized_probs)\n",
    "    if len(unnormalized_probs) > 0:\n",
    "        normalized_probs = unnormalized_probs / unnormalized_probs.sum()\n",
    "    else:\n",
    "        normalized_probs = unnormalized_probs\n",
    "        \n",
    "    return alias_setup(normalized_probs)\n",
    "    \n",
    "def get_alias_edge(graph, src, dst, p=1, q=1):\n",
    "    \"\"\"\n",
    "    get the alias edge setup lists for a given edge.\n",
    "    \"\"\"\n",
    "    # get the unnormalized probabilities with the second-order information\n",
    "    unnormalized_probs = list()\n",
    "    for dst_nbr in graph.neighbors(dst):\n",
    "        if dst_nbr == src: # distance is 0\n",
    "            unnormalized_probs.append(graph[dst][dst_nbr]['weight'] / p)\n",
    "        elif graph.has_edge(dst_nbr, src): # distance is 1\n",
    "            unnormalized_probs.append(graph[dst][dst_nbr]['weight'])\n",
    "        else: # distance is 2\n",
    "            unnormalized_probs.append(graph[dst][dst_nbr]['weight'] / q)\n",
    "    unnormalized_probs = np.array(unnormalized_probs)\n",
    "    if len(unnormalized_probs) > 0:\n",
    "        normalized_probs = unnormalized_probs / unnormalized_probs.sum()\n",
    "    else:\n",
    "        normalized_probs = unnormalized_probs\n",
    "\n",
    "    return alias_setup(normalized_probs)\n",
    "\n",
    "def preprocess_transition_probs(graph, p=1, q=1):\n",
    "    \"\"\"\n",
    "    preprocess transition probabilities for guiding the random walks.\n",
    "    \"\"\"\n",
    "    alias_nodes = dict()\n",
    "    for node in graph.nodes():\n",
    "        alias_nodes[node] = get_alias_node(graph, node)\n",
    "\n",
    "    alias_edges = dict()\n",
    "    for edge in graph.edges():\n",
    "        alias_edges[edge] = get_alias_edge(graph, edge[0], edge[1], p=p, q=q)\n",
    "\n",
    "    return alias_nodes, alias_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can use preprocess transition probabilities with the help of alias sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_nodes, alias_edges = preprocess_transition_probs(graph, p=2, q=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between DeepWalk and node2vec is how to generate random walks. The former only consider the first-order information while the latter also involves the second-order information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alias_draw(J, q):\n",
    "    \"\"\"\n",
    "    draw sample from a non-uniform discrete distribution using alias sampling.\n",
    "    \"\"\"\n",
    "    K = len(J)\n",
    "\n",
    "    kk = int(np.floor(np.random.rand() * K))\n",
    "    if np.random.rand() < q[kk]:\n",
    "        return kk\n",
    "    else:\n",
    "        return J[kk]\n",
    "\n",
    "    \n",
    "def fallback(walk, fetch_last_num=1):\n",
    "    if len(walk) > fetch_last_num:\n",
    "        walk.pop()\n",
    "        fetched = []\n",
    "        for i in range(fetch_last_num):\n",
    "            fetched.append(walk[-1-i])\n",
    "        return walk, fetched\n",
    "    else:\n",
    "        return [], [None for _ in range(fetch_last_num)]\n",
    "\n",
    "# generate the first order random walk\n",
    "def generate_first_order_random_walk(graph, alias_nodes, \n",
    "                                     walk_length=10, start_node=None, verbose=False, force=True, max_tried=10):\n",
    "    \"\"\"\n",
    "    simulate a random walk starting from start node and considering the first order information.\n",
    "    \"\"\"\n",
    "    if start_node == None:\n",
    "        start_node = np.random.choice(graph.nodes())\n",
    "    walk = [start_node]\n",
    "    cur = start_node\n",
    "    num_tried = 0\n",
    "    \n",
    "    while len(walk) < walk_length:\n",
    "        cur_nbrs = list(graph.neighbors(cur))\n",
    "        if len(cur_nbrs) > 0:\n",
    "            # sample the next node based on alias_nodes\n",
    "            cur = cur_nbrs[alias_draw(*alias_nodes[cur])]\n",
    "            walk.append(cur)\n",
    "        else:\n",
    "            if force:\n",
    "                walk, fetched = fallback(walk, fetch_last_num=1)\n",
    "                cur = fetched[0]\n",
    "                if len(walk) == 0:\n",
    "                    start_node = np.random.choice(graph.nodes())\n",
    "                    walk = [start_node]\n",
    "                    cur = start_node\n",
    "                num_tried += 1\n",
    "                if num_tried > max_tried: break\n",
    "            else:\n",
    "                break\n",
    "    if verbose: print(f'walk of lenght {len(walk)} generated with {num_tried} trails')\n",
    "    return walk\n",
    "    \n",
    "# second order random walk\n",
    "def generate_second_order_random_walk(graph, alias_nodes, alias_edges, \n",
    "                                      walk_length=10, start_node=None, verbose=False, force=True, max_tried=10):\n",
    "    \"\"\"\n",
    "    simulate a random walk starting from start node and considering the second order information.\n",
    "    \"\"\"\n",
    "    if start_node == None:\n",
    "        start_node = np.random.choice(graph.nodes())\n",
    "    walk = [start_node]\n",
    "    \n",
    "    prev = None\n",
    "    cur = start_node\n",
    "    num_tried = 0\n",
    "    \n",
    "    while len(walk) < walk_length:\n",
    "        cur_nbrs = list(graph.neighbors(cur))\n",
    "        if len(cur_nbrs) > 0:\n",
    "            if prev is None:\n",
    "                # sample the next node based on alias_nodes\n",
    "                prev, cur = cur, cur_nbrs[alias_draw(*alias_nodes[cur])]\n",
    "            else:\n",
    "                # sample the next node based on alias_edges\n",
    "                prev, cur = cur, cur_nbrs[alias_draw(*alias_edges[(prev, cur)])]\n",
    "            walk.append(cur)\n",
    "        else:\n",
    "            if force:\n",
    "                walk, (cur, prev) = fallback(walk, fetch_last_num=2)\n",
    "                if len(walk) == 0:\n",
    "                    start_node = np.random.choice(graph.nodes())\n",
    "                    walk = [start_node]\n",
    "                    cur = start_node\n",
    "                    prev = None\n",
    "                num_tried += 1\n",
    "                if num_tried > max_tried: break\n",
    "            else:\n",
    "                break\n",
    "    if verbose: print(f'walk of lenght {len(walk)} generated with {num_tried} trails')\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to generate a first-order random walk and a second-order random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk of lenght 100 generated with 5 trails\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['N6ZTMIue-2b30CJv2tyPGg',\n",
       " 'iDlkZO2iILS8Jwfdy7DP9A',\n",
       " 'AtDUaCAPuSKR6E6QaSmmow',\n",
       " 'UYcmGbelzRa0Q6JqzLoguw',\n",
       " '9Ms5wpxVloadWFvDbb77kg',\n",
       " 'jRyO2V1pA4CdVVqCIOPc1Q',\n",
       " 'xhhE0txKwQtRzgQVVdKkvg',\n",
       " 's-591-mtIyP7F1Lffw98jw',\n",
       " 'bLbSNkLggFnqwNNzzq-Ijw',\n",
       " 'xFSLb_pxXta5G4oaRB1ylQ',\n",
       " 'm-BZLIIh5PCAKnzH0qj_0Q',\n",
       " 'jRyO2V1pA4CdVVqCIOPc1Q',\n",
       " 'm-BZLIIh5PCAKnzH0qj_0Q',\n",
       " 'IGBilULpgNHfKitLfrs7Hw',\n",
       " '2EuPAGalYnP7eSxPgFCNDg',\n",
       " 'BQkC6RneYfvfG6wRe0hsvQ',\n",
       " 'bLbSNkLggFnqwNNzzq-Ijw',\n",
       " 'VgG_4NU41eZbpidLyfk3vw',\n",
       " 'bLbSNkLggFnqwNNzzq-Ijw',\n",
       " '2JDWKHpR0g4QA4MHmFDprg',\n",
       " 'yyDp7MZ2st7p0fOQuFYpcA',\n",
       " 'w7RP1MZad3YO7Vjgp3s3Dg',\n",
       " 'DWpDDBJvO_fLqhwEwY2joQ',\n",
       " '9bvlW5Gos1kxzvcM3c-12w',\n",
       " 'DWpDDBJvO_fLqhwEwY2joQ',\n",
       " 'H-ROZEeDUP5j4DjLXn8iOA',\n",
       " 'zoyb93pskMhDgXZgv-DKtA',\n",
       " 'AmMd7xpnaf8axS_roCBFRw',\n",
       " 'bLbSNkLggFnqwNNzzq-Ijw',\n",
       " 'q-v8elVPvKz0KvK69QSj1Q',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " '_iQh8_WAt-FBmjGB_fJQ5w',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'BfnYXZEfWNdmW9VbWVeg7Q',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'BfnYXZEfWNdmW9VbWVeg7Q',\n",
       " '68rI8SriEjPYvGk81K1Dhw',\n",
       " 'BfnYXZEfWNdmW9VbWVeg7Q',\n",
       " 'lt9vlWEaHsILoBBOEwX4MA',\n",
       " 'BfnYXZEfWNdmW9VbWVeg7Q',\n",
       " 'FKGU3zgaImSKrXHVMh3YEA',\n",
       " 'BfnYXZEfWNdmW9VbWVeg7Q',\n",
       " 'FKGU3zgaImSKrXHVMh3YEA',\n",
       " 'BfnYXZEfWNdmW9VbWVeg7Q',\n",
       " 'yW6MoCSRNnqyehn3_EXnSg',\n",
       " 'BfnYXZEfWNdmW9VbWVeg7Q',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'bAK3Fl4aHEuCBfD_kMa7XQ',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'N7E-CfqdME28dakWdEKNvw',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'N7E-CfqdME28dakWdEKNvw',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'BfnYXZEfWNdmW9VbWVeg7Q',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'bAK3Fl4aHEuCBfD_kMa7XQ',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'wavdGQBo8x1sozm5KVvy6A',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'wavdGQBo8x1sozm5KVvy6A',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'q-v8elVPvKz0KvK69QSj1Q',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " '0WEEY4WHF4rvNkIdTHfSkg',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " '0WEEY4WHF4rvNkIdTHfSkg',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'wavdGQBo8x1sozm5KVvy6A',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'bAK3Fl4aHEuCBfD_kMa7XQ',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'YyzBNC_5aBhJi-aJWiEMvw',\n",
       " 'PkeDOqXbgEOkR-aKUHoQ_A',\n",
       " 'N7E-CfqdME28dakWdEKNvw',\n",
       " 'iDlkZO2iILS8Jwfdy7DP9A',\n",
       " 'DzyBToexbfik0zt7ppky-Q',\n",
       " 'G-_KF_Ul4d3WGEa-G0Iq4g',\n",
       " 'DzyBToexbfik0zt7ppky-Q',\n",
       " 'iDlkZO2iILS8Jwfdy7DP9A',\n",
       " 'N7E-CfqdME28dakWdEKNvw',\n",
       " 'MVvWOlVgOfRAtP41-A-g2w',\n",
       " 'MQwSyZ2MZ6N7rtAmphZCow',\n",
       " '-HH9X240K3SaBq4xzWGrOg',\n",
       " 'MQwSyZ2MZ6N7rtAmphZCow',\n",
       " 'Za04ZUz8FQYyG67Mmg50Hw',\n",
       " 'aGJyYiJNYaz8a-Boa0BOlA',\n",
       " 's79vzEzqavL_29pmraXZBA',\n",
       " 'Za04ZUz8FQYyG67Mmg50Hw',\n",
       " 'el3TmKFEFzZOcNbCw2FNlQ',\n",
       " '3NnPbhmv_vEfPTBp2pnn9Q',\n",
       " '9Ms5wpxVloadWFvDbb77kg',\n",
       " 'Bj_MarPEKBe2xN12YimekQ',\n",
       " 'xFSLb_pxXta5G4oaRB1ylQ',\n",
       " '9bvlW5Gos1kxzvcM3c-12w',\n",
       " 'nkX9riHbrASlZcTfnAMGiw',\n",
       " '9bvlW5Gos1kxzvcM3c-12w',\n",
       " 'UDFIZXP0kOb2xKoYToTS6w',\n",
       " '4ONcRRisDZkbV1cviA7nFw',\n",
       " 'UDFIZXP0kOb2xKoYToTS6w',\n",
       " 'Zoec9wehLFa8CV1JnCCVug']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 行100步途中遇到的所有nodes, if we found 100 nodes, will return\n",
    "generate_first_order_random_walk(graph, alias_nodes=alias_nodes,\n",
    "                                 start_node=\"N6ZTMIue-2b30CJv2tyPGg\", walk_length=100, force=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk of lenght 78 generated with 11 trails\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['N6ZTMIue-2b30CJv2tyPGg',\n",
       " 'iDlkZO2iILS8Jwfdy7DP9A',\n",
       " 'N7E-CfqdME28dakWdEKNvw',\n",
       " 'gqL5KBs2oS7qobnyd99iKg',\n",
       " 'zTK1nPD2Hpa-ksSXsE-JzQ',\n",
       " 'MQwSyZ2MZ6N7rtAmphZCow',\n",
       " 'wUgRsMwL-BCreuMBgmFdWg',\n",
       " 'AmMd7xpnaf8axS_roCBFRw',\n",
       " 'F2av57ztcbYiPADtT-YpdA',\n",
       " '0d7gFJUi4cV3I7j1dHn9fQ',\n",
       " 'F2av57ztcbYiPADtT-YpdA',\n",
       " 'AmMd7xpnaf8axS_roCBFRw',\n",
       " 'xhhE0txKwQtRzgQVVdKkvg',\n",
       " 'JXHrhT72U6sZJQSkFfNzjw',\n",
       " 'xhhE0txKwQtRzgQVVdKkvg',\n",
       " 'Bj_MarPEKBe2xN12YimekQ',\n",
       " 'bLbSNkLggFnqwNNzzq-Ijw',\n",
       " 'doGsaahbqD7ePHP19UsDsg',\n",
       " 'UYcmGbelzRa0Q6JqzLoguw',\n",
       " 'renPzRDqMZpMaHiCD_e1_A',\n",
       " 'xhhE0txKwQtRzgQVVdKkvg',\n",
       " 'renPzRDqMZpMaHiCD_e1_A',\n",
       " 'xFSLb_pxXta5G4oaRB1ylQ',\n",
       " 'bLbSNkLggFnqwNNzzq-Ijw',\n",
       " 'xFSLb_pxXta5G4oaRB1ylQ',\n",
       " 'renPzRDqMZpMaHiCD_e1_A',\n",
       " 'xhhE0txKwQtRzgQVVdKkvg',\n",
       " 'IGBilULpgNHfKitLfrs7Hw',\n",
       " 'renPzRDqMZpMaHiCD_e1_A',\n",
       " 's-591-mtIyP7F1Lffw98jw',\n",
       " '2EuPAGalYnP7eSxPgFCNDg',\n",
       " 'xhhE0txKwQtRzgQVVdKkvg',\n",
       " 'Bj_MarPEKBe2xN12YimekQ',\n",
       " 'JcNSd3dXmIMVHP2CUpvMHA',\n",
       " 'kjaUSiRWhR9bF9KxOMbVvg',\n",
       " 'SVH0qJBvYGLxrt6YuUdyyw',\n",
       " 'Go1C5ZgO0jackKNTHxNHJw',\n",
       " 'SVH0qJBvYGLxrt6YuUdyyw',\n",
       " 'Go1C5ZgO0jackKNTHxNHJw',\n",
       " 'SVH0qJBvYGLxrt6YuUdyyw',\n",
       " 'kjaUSiRWhR9bF9KxOMbVvg',\n",
       " 'AmMd7xpnaf8axS_roCBFRw',\n",
       " 'Vq73g5hdDBdxdBOfkEYqyw',\n",
       " '5jJjY5_R06Og56VfjIc66A',\n",
       " 'SlgpAnj2gQd44EM_Uq6DkQ',\n",
       " '2m2MNnlOdofofmUs-hYTJQ',\n",
       " 'SlgpAnj2gQd44EM_Uq6DkQ',\n",
       " 'DXh8yxwZCg5Ckj5kmDvKXw',\n",
       " 'jRyO2V1pA4CdVVqCIOPc1Q',\n",
       " 'Bj_MarPEKBe2xN12YimekQ',\n",
       " 'JcNSd3dXmIMVHP2CUpvMHA',\n",
       " 'tH0uKD-vNwMoEc3Xk3Cbdg',\n",
       " 'renPzRDqMZpMaHiCD_e1_A',\n",
       " 'xFSLb_pxXta5G4oaRB1ylQ',\n",
       " 'BQkC6RneYfvfG6wRe0hsvQ',\n",
       " 'f-ysez9SJSosLUON1BihWg',\n",
       " 'AmMd7xpnaf8axS_roCBFRw',\n",
       " 'NkE-ORKVsdVAtwOGuBsbsw',\n",
       " 'AmMd7xpnaf8axS_roCBFRw',\n",
       " '2EuPAGalYnP7eSxPgFCNDg',\n",
       " 'AmMd7xpnaf8axS_roCBFRw',\n",
       " 'NkE-ORKVsdVAtwOGuBsbsw',\n",
       " 'AmMd7xpnaf8axS_roCBFRw',\n",
       " 'Uit6vvFxthHbwOHIYI0sfQ',\n",
       " '3NnPbhmv_vEfPTBp2pnn9Q',\n",
       " '9Ms5wpxVloadWFvDbb77kg',\n",
       " 'tH0uKD-vNwMoEc3Xk3Cbdg',\n",
       " 'cRDQuBEgxaYQoSPHAiEgHQ',\n",
       " 'tH0uKD-vNwMoEc3Xk3Cbdg',\n",
       " 'UYcmGbelzRa0Q6JqzLoguw',\n",
       " 'Ksp1e9Dw0Jcog_ZBD3-45g',\n",
       " 'cdCvHUFdssePxowTHIo3dQ',\n",
       " 'UYcmGbelzRa0Q6JqzLoguw',\n",
       " 'cJh4F1zFNJb2wXCNT1uNWQ',\n",
       " '2EuPAGalYnP7eSxPgFCNDg',\n",
       " 'cJh4F1zFNJb2wXCNT1uNWQ',\n",
       " 'tH0uKD-vNwMoEc3Xk3Cbdg',\n",
       " 'FAjCZoxiGw9HJKueB8YWTg']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_second_order_random_walk(graph, alias_nodes=alias_nodes, alias_edges=alias_edges,\n",
    "                                  start_node=\"N6ZTMIue-2b30CJv2tyPGg\", walk_length=100, force=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Embedding Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deepwalk(graph, alias_nodes, node_dim=10, num_walks=10, walk_length=10):\n",
    "    \"\"\"\n",
    "    build a deepwalk model\n",
    "    \"\"\"\n",
    "    print(\"building a DeepWalk model...\", end=\"\\t\")\n",
    "    st = time.time()\n",
    "    np.random.seed(0)\n",
    "    nodes = list(graph.nodes())\n",
    "    walks = list()\n",
    "    # generate random walks\n",
    "    for walk_iter in range(num_walks):\n",
    "        np.random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(generate_first_order_random_walk(graph, alias_nodes, walk_length=walk_length, start_node=node))\n",
    "        \n",
    "    walk_lens = [len(w) for w in walks]\n",
    "    if len(walk_lens) > 0:\n",
    "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
    "    else:\n",
    "        avg_walk_len = 0.0\n",
    "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len), end=\"\\t\")\n",
    "    \n",
    "    # train a skip-gram model for these walks\n",
    "    model = Word2Vec(walks, size=node_dim, window=3, min_count=0, sg=1, workers=os.cpu_count(), iter=10)\n",
    "    print(\"trainig time: %.4f\" % (time.time()-st))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_node2vec(graph, alias_nodes, alias_edges, node_dim=10, num_walks=10, walk_length=10, seed=1):\n",
    "    \"\"\"\n",
    "    build a node2vec model\n",
    "    \"\"\"\n",
    "    print(\"building a node2vec model...\", end=\"\\t\")\n",
    "    st = time.time()\n",
    "    np.random.seed(0)\n",
    "    nodes = list(graph.nodes())\n",
    "    walks = list()\n",
    "    # generate random walks\n",
    "    for walk_iter in range(num_walks):\n",
    "        np.random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(generate_second_order_random_walk(graph, alias_nodes, alias_edges, walk_length=walk_length, start_node=node))\n",
    "            \n",
    "    walk_lens = [len(w) for w in walks]\n",
    "    if len(walk_lens) > 0:\n",
    "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
    "    else:\n",
    "        avg_walk_len = 0.0    \n",
    "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len), end=\"\\t\")\n",
    "    \n",
    "    # train a skip-gram model for these walks\n",
    "    model = Word2Vec(walks, size=node_dim, window=3, min_count=0, sg=1, workers=os.cpu_count(), iter=10, seed=1)\n",
    "    print(\"trainig time: %.4f\" % (time.time()-st))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can build a DeepWalk model and a node2vec model. Here we set p=q=0.5 so that the walker will not go very far away from the start node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building a DeepWalk model...\tnumber of walks: 39300\taverage walk length: 8.5928\t"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ac831513375c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeepwalk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_deepwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malias_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_walks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalk_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-1facdf842d49>\u001b[0m in \u001b[0;36mbuild_deepwalk\u001b[0;34m(graph, alias_nodes, node_dim, num_walks, walk_length)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# train a skip-gram model for these walks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainig time: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'size'"
     ]
    }
   ],
   "source": [
    "deepwalk = build_deepwalk(graph, alias_nodes, node_dim=10, num_walks=10, walk_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building a node2vec model...\tnumber of walks: 39300\taverage walk length: 9.8948\ttrainig time: 13.6509\n"
     ]
    }
   ],
   "source": [
    "node2vec = build_node2vec(graph, alias_nodes, alias_edges, node_dim=10, num_walks=10, walk_length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_sim(model, u, v):\n",
    "    \"\"\"\n",
    "    get the cosine similarity between two nodes\n",
    "    \"\"\"\n",
    "    try:\n",
    "        u = model.wv[u]\n",
    "        v = model.wv[v]\n",
    "        return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_auc_score(model, true_edges, false_edges):\n",
    "    \"\"\"\n",
    "    get the auc score\n",
    "    \"\"\"\n",
    "    y_true = [1] * len(true_edges) + [0] * len(false_edges)\n",
    "    \n",
    "    y_score = list()\n",
    "    for e in true_edges:\n",
    "        y_score.append(get_cosine_sim(model, e[0], e[1]))\n",
    "    for e in false_edges:\n",
    "        y_score.append(get_cosine_sim(model, e[0], e[1]))\n",
    "    \n",
    "    return roc_auc_score(y_true, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try them over a Real-life Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the node embeddings of three nodes, and cosine similarities of two edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node embedding (\"N6ZTMIue-2b30CJv2tyPGg\"): [-0.36232373 -0.72744584 -0.47010353  0.17939933 -0.04121303  0.92036295\n",
      "  0.8701034  -0.97390413  0.69072515  0.7475717 ]\n",
      "node embedding (\"N7E-CfqdME28dakWdEKNvw\"): [ 0.5813705  -1.162643   -0.00645171 -0.22482896  0.17096843  0.9237789\n",
      "  1.5884651  -1.3143146   1.1850793   1.0500975 ]\n",
      "node embedding (\"MmlJSLDg-IFaeXb5wdJbgg\"): [ 1.0545577   0.11629698  0.23369302 -3.375658    0.02999506  2.4090235\n",
      "  0.42507368 -1.683669    0.5016573  -0.13335882]\n",
      "true edge (\"N6ZTMIue-2b30CJv2tyPGg\", \"N7E-CfqdME28dakWdEKNvw\"): 0.87795585\n",
      "false edge (\"N6ZTMIue-2b30CJv2tyPGg\", \"MmlJSLDg-IFaeXb5wdJbgg\"): 0.3330828\n"
     ]
    }
   ],
   "source": [
    "print(\"node embedding (\\\"N6ZTMIue-2b30CJv2tyPGg\\\"):\",\n",
    "      deepwalk.wv[\"N6ZTMIue-2b30CJv2tyPGg\"])\n",
    "print(\"node embedding (\\\"N7E-CfqdME28dakWdEKNvw\\\"):\",\n",
    "      deepwalk.wv[\"N7E-CfqdME28dakWdEKNvw\"])\n",
    "print(\"node embedding (\\\"MmlJSLDg-IFaeXb5wdJbgg\\\"):\",\n",
    "      deepwalk.wv[\"MmlJSLDg-IFaeXb5wdJbgg\"])\n",
    "print(\"true edge (\\\"N6ZTMIue-2b30CJv2tyPGg\\\", \\\"N7E-CfqdME28dakWdEKNvw\\\"):\",\n",
    "      get_cosine_sim(deepwalk, \"N6ZTMIue-2b30CJv2tyPGg\", \"N7E-CfqdME28dakWdEKNvw\"))\n",
    "print(\"false edge (\\\"N6ZTMIue-2b30CJv2tyPGg\\\", \\\"MmlJSLDg-IFaeXb5wdJbgg\\\"):\",\n",
    "      get_cosine_sim(deepwalk, \"N6ZTMIue-2b30CJv2tyPGg\", \"MmlJSLDg-IFaeXb5wdJbgg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link prediction is a task to prediction unseen edges based on graph information. Let's use cross validation to check their performance in the link prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case(kfold=5, node_dim=10, num_walks=10, walk_length=5, p=0.5, q=0.5):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    deepwalk_auc_scores = list()\n",
    "    node2vec_auc_scores = list()\n",
    "    kf = KFold(n_splits=kfold, shuffle=True)\n",
    "    for k, (train_idx, valid_idx) in enumerate(kf.split(edges)):\n",
    "        # split edges into training and validation\n",
    "        train_edges = [edges[idx] for idx in train_idx]\n",
    "        valid_edges = [edges[idx] for idx in valid_idx]\n",
    "        # generate the same validation size of false edges\n",
    "        false_edges = generate_false_edges(edges, num_false_edges=len(valid_edges))\n",
    "\n",
    "        # construct the graph and preprocess transition probabilities\n",
    "        graph = construct_graph_from_edges(train_edges)\n",
    "        alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
    "\n",
    "        # build models and get auc scores\n",
    "        model = build_deepwalk(graph, alias_nodes,\n",
    "                               node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
    "        deepwalk_auc_scores.append(get_auc_score(model, valid_edges, false_edges))\n",
    "\n",
    "        model = build_node2vec(graph, alias_nodes, alias_edges,\n",
    "                               node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
    "        node2vec_auc_scores.append(get_auc_score(model, valid_edges, false_edges))\n",
    "\n",
    "    deepwalk_auc_scores = np.array(deepwalk_auc_scores)\n",
    "    node2vec_auc_scores = np.array(node2vec_auc_scores)\n",
    "    print(\"DeepWalk: avg auc score: %.4f\\tstd: %.4f\" % (deepwalk_auc_scores.mean(), deepwalk_auc_scores.std()))\n",
    "    print(\"node2vec: avg auc score: %.4f\\tstd: %.4f\" % (node2vec_auc_scores.mean(), node2vec_auc_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 3574\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 7148\taverage walk length: 2.0000\ttrainig time: 1.2047\n",
      "building a node2vec model...\tnumber of walks: 7148\taverage walk length: 2.0000\ttrainig time: 1.2289\n",
      "number of nodes: 3610\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 7220\taverage walk length: 2.0000\ttrainig time: 1.1850\n",
      "building a node2vec model...\tnumber of walks: 7220\taverage walk length: 2.0000\ttrainig time: 1.2523\n",
      "number of nodes: 3639\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 7278\taverage walk length: 2.0000\ttrainig time: 1.2255\n",
      "building a node2vec model...\tnumber of walks: 7278\taverage walk length: 2.0000\ttrainig time: 1.2693\n",
      "number of nodes: 3582\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 7164\taverage walk length: 2.0000\ttrainig time: 1.2548\n",
      "building a node2vec model...\tnumber of walks: 7164\taverage walk length: 2.0000\ttrainig time: 1.2015\n",
      "number of nodes: 3600\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 7200\taverage walk length: 2.0000\ttrainig time: 1.1869\n",
      "building a node2vec model...\tnumber of walks: 7200\taverage walk length: 2.0000\ttrainig time: 1.2194\n",
      "DeepWalk: avg auc score: 0.5051\tstd: 0.0036\n",
      "node2vec: avg auc score: 0.5051\tstd: 0.0036\n"
     ]
    }
   ],
   "source": [
    "case(kfold=5, node_dim=2, num_walks=2, walk_length=2, p=0.5, q=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 3574\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 17870\taverage walk length: 4.2996\ttrainig time: 2.4550\n",
      "building a node2vec model...\tnumber of walks: 17870\taverage walk length: 4.9248\ttrainig time: 5.3298\n",
      "number of nodes: 3610\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 18050\taverage walk length: 4.3637\ttrainig time: 2.5155\n",
      "building a node2vec model...\tnumber of walks: 18050\taverage walk length: 4.9461\ttrainig time: 5.2827\n",
      "number of nodes: 3639\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 18195\taverage walk length: 4.3013\ttrainig time: 2.5971\n",
      "building a node2vec model...\tnumber of walks: 18195\taverage walk length: 4.9227\ttrainig time: 5.6862\n",
      "number of nodes: 3582\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 17910\taverage walk length: 4.3045\ttrainig time: 2.4990\n",
      "building a node2vec model...\tnumber of walks: 17910\taverage walk length: 4.9412\ttrainig time: 5.6011\n",
      "number of nodes: 3600\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 18000\taverage walk length: 4.3323\ttrainig time: 2.4989\n",
      "building a node2vec model...\tnumber of walks: 18000\taverage walk length: 4.9142\ttrainig time: 5.3990\n",
      "DeepWalk: avg auc score: 0.7865\tstd: 0.0108\n",
      "node2vec: avg auc score: 0.7942\tstd: 0.0094\n"
     ]
    }
   ],
   "source": [
    "case(kfold=5, node_dim=5, num_walks=5, walk_length=5, p=0.5, q=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 3574\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 17870\taverage walk length: 4.2996\ttrainig time: 2.5157\n",
      "building a node2vec model...\tnumber of walks: 17870\taverage walk length: 4.9193\ttrainig time: 5.3296\n",
      "number of nodes: 3610\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 18050\taverage walk length: 4.3637\ttrainig time: 2.6554\n",
      "building a node2vec model...\tnumber of walks: 18050\taverage walk length: 4.9467\ttrainig time: 5.2629\n",
      "number of nodes: 3639\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 18195\taverage walk length: 4.3013\ttrainig time: 2.6548\n",
      "building a node2vec model...\tnumber of walks: 18195\taverage walk length: 4.9294\ttrainig time: 5.5435\n",
      "number of nodes: 3582\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 17910\taverage walk length: 4.3045\ttrainig time: 2.5526\n",
      "building a node2vec model...\tnumber of walks: 17910\taverage walk length: 4.9456\ttrainig time: 5.4681\n",
      "number of nodes: 3600\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 18000\taverage walk length: 4.3323\ttrainig time: 2.5329\n",
      "building a node2vec model...\tnumber of walks: 18000\taverage walk length: 4.9137\ttrainig time: 5.2510\n",
      "DeepWalk: avg auc score: 0.7856\tstd: 0.0091\n",
      "node2vec: avg auc score: 0.7953\tstd: 0.0059\n"
     ]
    }
   ],
   "source": [
    "case(kfold=5, node_dim=5, num_walks=5, walk_length=5, p=0.25, q=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 3574\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 17870\taverage walk length: 4.2996\ttrainig time: 2.4469\n",
      "building a node2vec model...\tnumber of walks: 17870\taverage walk length: 4.9239\ttrainig time: 5.3298\n",
      "number of nodes: 3610\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 18050\taverage walk length: 4.3637\ttrainig time: 2.6087\n",
      "building a node2vec model...\tnumber of walks: 18050\taverage walk length: 4.9474\ttrainig time: 5.2453\n",
      "number of nodes: 3639\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 18195\taverage walk length: 4.3013\ttrainig time: 2.7338\n",
      "building a node2vec model...\tnumber of walks: 18195\taverage walk length: 4.9265\ttrainig time: 6.2089\n",
      "number of nodes: 3582\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 17910\taverage walk length: 4.3045\ttrainig time: 2.5516\n",
      "building a node2vec model...\tnumber of walks: 17910\taverage walk length: 4.9487\ttrainig time: 5.8662\n",
      "number of nodes: 3600\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 18000\taverage walk length: 4.3323\ttrainig time: 2.6437\n",
      "building a node2vec model...\tnumber of walks: 18000\taverage walk length: 4.9128\ttrainig time: 5.3032\n",
      "DeepWalk: avg auc score: 0.7872\tstd: 0.0073\n",
      "node2vec: avg auc score: 0.7942\tstd: 0.0075\n"
     ]
    }
   ],
   "source": [
    "case(kfold=5, node_dim=5, num_walks=5, walk_length=5, p=1, q=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 3574\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 35740\taverage walk length: 8.3403\ttrainig time: 5.3430\n",
      "building a node2vec model...\tnumber of walks: 35740\taverage walk length: 9.6946\ttrainig time: 11.5061\n",
      "number of nodes: 3610\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 36100\taverage walk length: 8.5036\ttrainig time: 5.2952\n",
      "building a node2vec model...\tnumber of walks: 36100\taverage walk length: 9.8084\ttrainig time: 11.0941\n",
      "number of nodes: 3639\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 36390\taverage walk length: 8.4013\ttrainig time: 5.5094\n",
      "building a node2vec model...\tnumber of walks: 36390\taverage walk length: 9.7810\ttrainig time: 11.5867\n",
      "number of nodes: 3582\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 35820\taverage walk length: 8.3423\ttrainig time: 5.2447\n",
      "building a node2vec model...\tnumber of walks: 35820\taverage walk length: 9.7650\ttrainig time: 11.5482\n",
      "number of nodes: 3600\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 36000\taverage walk length: 8.3216\ttrainig time: 5.2876\n",
      "building a node2vec model...\tnumber of walks: 36000\taverage walk length: 9.6098\ttrainig time: 11.2249\n",
      "DeepWalk: avg auc score: 0.7999\tstd: 0.0084\n",
      "node2vec: avg auc score: 0.8024\tstd: 0.0079\n"
     ]
    }
   ],
   "source": [
    "case(kfold=5, node_dim=10, num_walks=10, walk_length=10, p=0.5, q=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 3574\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 35740\taverage walk length: 8.3403\ttrainig time: 5.2807\n",
      "building a node2vec model...\tnumber of walks: 35740\taverage walk length: 9.6844\ttrainig time: 11.4601\n",
      "number of nodes: 3610\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 36100\taverage walk length: 8.5036\ttrainig time: 5.4052\n",
      "building a node2vec model...\tnumber of walks: 36100\taverage walk length: 9.7904\ttrainig time: 11.0065\n",
      "number of nodes: 3639\n",
      "number of edges: 12550\n",
      "building a DeepWalk model...\tnumber of walks: 36390\taverage walk length: 8.4013\ttrainig time: 5.7579\n",
      "building a node2vec model...\tnumber of walks: 36390\taverage walk length: 9.7606\ttrainig time: 11.8396\n",
      "number of nodes: 3582\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 35820\taverage walk length: 8.3423\ttrainig time: 5.2714\n",
      "building a node2vec model...\tnumber of walks: 35820\taverage walk length: 9.7490\ttrainig time: 11.4608\n",
      "number of nodes: 3600\n",
      "number of edges: 12551\n",
      "building a DeepWalk model...\tnumber of walks: 36000\taverage walk length: 8.3216\ttrainig time: 5.2576\n",
      "building a node2vec model...\tnumber of walks: 36000\taverage walk length: 9.5863\ttrainig time: 11.4127\n",
      "DeepWalk: avg auc score: 0.8020\tstd: 0.0053\n",
      "node2vec: avg auc score: 0.8043\tstd: 0.0049\n"
     ]
    }
   ],
   "source": [
    "case(kfold=5, node_dim=10, num_walks=10, walk_length=10, p=0.25, q=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
