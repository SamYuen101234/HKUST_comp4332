{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Dot, Dropout, Embedding, Input, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "\n",
    "# I use Tensorflow 2.x here so that the Keras is included as part of the Tensorflow\n",
    "# If you install the Keras aloneside you can just use the following imports\n",
    "\n",
    "# from keras.layers import Concatenate, Dense, Dot, Dropout, Embedding, Input, Reshape\n",
    "# from keras.models import Model\n",
    "# from keras.callbacks import Callback, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def rmse(pred, actual):\n",
    "    # Ignore ratings with value zero.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(pred, actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ec8f38aa91755dcf5837020d022ad384</td>\n",
       "      <td>ecaa90564e18dca1c7b653038f71d6bf</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64fe4dd0a489c9b96a3e8d7fbd337888</td>\n",
       "      <td>ef118bb0ae1fc369e1f47d1b34f6acee</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a49909b39426ebb3538aa837b5b88840</td>\n",
       "      <td>e8b182a923810d52981aa02d56dde799</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a56726d5676d647e42e2aca54f21b075</td>\n",
       "      <td>250040e979eae9ef5912aa5a1d285e4e</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3e19d8260e655ba87bea0922bac92266</td>\n",
       "      <td>e02880faf4d42fe1df7bd370fb1c787b</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id                       business_id  stars\n",
       "0  ec8f38aa91755dcf5837020d022ad384  ecaa90564e18dca1c7b653038f71d6bf    1.0\n",
       "1  64fe4dd0a489c9b96a3e8d7fbd337888  ef118bb0ae1fc369e1f47d1b34f6acee    5.0\n",
       "2  a49909b39426ebb3538aa837b5b88840  e8b182a923810d52981aa02d56dde799    5.0\n",
       "3  a56726d5676d647e42e2aca54f21b075  250040e979eae9ef5912aa5a1d285e4e    5.0\n",
       "4  3e19d8260e655ba87bea0922bac92266  e02880faf4d42fe1df7bd370fb1c787b    4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "valid_df = pd.read_csv(\"data/valid.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4981 10845\n"
     ]
    }
   ],
   "source": [
    "#Get the set of all user ids and set of all business ids in train set\n",
    "user_set = set(train_df.user_id.unique())\n",
    "business_set = set(train_df.business_id.unique())\n",
    "\n",
    "#Build user vocabulary\n",
    "user_vocab = dict(zip(user_set, range(1, len(user_set) + 1)))\n",
    "#reserve the first row of the embedding matrix for users unseen in the training set\n",
    "user_vocab['unk'] = 0\n",
    "n_users = len(user_vocab)\n",
    "\n",
    "#Build business vocabulary\n",
    "business_vocab = dict(zip(business_set, range(1, len(business_set) + 1)))\n",
    "#reserve the first row of the embedding matrix for businesses unseen in the training set\n",
    "business_vocab['unk'] = 0\n",
    "n_items = len(business_vocab)\n",
    "\n",
    "print(n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = train_df.user_id.apply(lambda x: user_vocab[x]).values\n",
    "train_items = train_df.business_id.apply(lambda x: business_vocab[x]).values\n",
    "valid_users = valid_df.user_id.apply(lambda x: user_vocab[x] if x in user_vocab else 0).values\n",
    "valid_items = valid_df.business_id.apply(lambda x: business_vocab[x] if x in business_vocab else 0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = train_df.stars.values\n",
    "valid_ratings = valid_df.stars.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 5.0\n"
     ]
    }
   ],
   "source": [
    "print(np.min(train_ratings), np.max(train_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User/Item CF with `scipy` sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (2721, 4836)\t1.0\n",
      "  (3755, 3990)\t5.0\n",
      "  (306, 7858)\t5.0\n",
      "  (2600, 8050)\t5.0\n",
      "  (3729, 6251)\t4.0\n",
      "  (3565, 539)\t5.0\n",
      "  (4209, 1232)\t4.0\n",
      "  (1774, 1798)\t2.0\n",
      "  (2135, 4902)\t5.0\n",
      "  (1802, 3572)\t5.0\n",
      "  (4692, 4967)\t3.0\n",
      "  (1010, 8620)\t5.0\n",
      "  (1545, 518)\t5.0\n",
      "  (2577, 5549)\t5.0\n",
      "  (4617, 3073)\t5.0\n",
      "  (1717, 1130)\t4.0\n",
      "  (3699, 9809)\t4.0\n",
      "  (2580, 3902)\t5.0\n",
      "  (1793, 2147)\t5.0\n",
      "  (4692, 3671)\t5.0\n",
      "  (1147, 10625)\t5.0\n",
      "  (642, 6342)\t2.0\n",
      "  (258, 8506)\t4.0\n",
      "  (4740, 3915)\t4.0\n",
      "  (305, 5287)\t3.0\n",
      "  :\t:\n",
      "  (4627, 3040)\t3.0\n",
      "  (2004, 10796)\t4.0\n",
      "  (4671, 5555)\t4.0\n",
      "  (3026, 10042)\t5.0\n",
      "  (1819, 10705)\t4.0\n",
      "  (3028, 10394)\t2.0\n",
      "  (1063, 9651)\t4.0\n",
      "  (476, 3114)\t3.0\n",
      "  (899, 10272)\t4.0\n",
      "  (320, 1196)\t3.0\n",
      "  (3434, 3106)\t5.0\n",
      "  (1557, 1631)\t4.0\n",
      "  (1399, 3732)\t2.0\n",
      "  (663, 1980)\t5.0\n",
      "  (529, 2535)\t3.0\n",
      "  (464, 6652)\t5.0\n",
      "  (68, 2649)\t5.0\n",
      "  (1335, 5955)\t5.0\n",
      "  (4284, 4614)\t5.0\n",
      "  (3242, 8757)\t5.0\n",
      "  (2322, 2136)\t5.0\n",
      "  (3645, 5952)\t4.0\n",
      "  (2159, 2822)\t4.0\n",
      "  (274, 7588)\t4.0\n",
      "  (122, 9793)\t5.0\n",
      "(4981, 10845)\n",
      "77.18530415579201\n",
      "35.45043798985708\n"
     ]
    }
   ],
   "source": [
    "train_matrix_sparse = coo_matrix((train_ratings, (train_users, train_items)))\n",
    "print(train_matrix_sparse)\n",
    "\n",
    "train_matrix = train_matrix_sparse.toarray()\n",
    "print(train_matrix.shape)\n",
    "print(train_matrix.sum()/n_users)\n",
    "print(train_matrix.sum()/n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User CF v.s. Item CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_v2(X, Y):\n",
    "    m, d1 = X.shape\n",
    "    n, d2 = Y.shape\n",
    "    ans = np.zeros((m,n))\n",
    "    assert d1 == d2\n",
    "    for i in trange(n):\n",
    "        for j in range(m):\n",
    "            valid_ids = (X[i] > 0) & (Y[j] > 0)\n",
    "            x = X[i, valid_ids]\n",
    "            y = Y[j, valid_ids]\n",
    "            ans[i,j] = x.dot(y) / (norm(x) * norm(y)+1e-6)\n",
    "    return ans\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 203/4981 [00:30<12:07,  6.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-2a51bca50d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-d2d60e7d005c>\u001b[0m in \u001b[0;36mcosine_similarity_v2\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mvalid_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "user_sim = cosine_similarity_v2(train_matrix, train_matrix)\n",
    "\n",
    "print(user_sim.shape)\n",
    "print(user_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4981, 4981)\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00 -1.86236136e-03 ... -1.20710945e-03\n",
      "  -7.34438352e-04 -1.55524801e-03]\n",
      " [ 0.00000000e+00 -1.86236136e-03  1.00000000e+00 ...  2.33066014e-02\n",
      "  -2.54405630e-03 -5.38729834e-03]\n",
      " ...\n",
      " [ 0.00000000e+00 -1.20710945e-03  2.33066014e-02 ...  1.00000000e+00\n",
      "  -1.64895732e-03 -3.49183508e-03]\n",
      " [ 0.00000000e+00 -7.34438352e-04 -2.54405630e-03 ... -1.64895732e-03\n",
      "   1.00000000e+00 -2.12452781e-03]\n",
      " [ 0.00000000e+00 -1.55524801e-03 -5.38729834e-03 ... -3.49183508e-03\n",
      "  -2.12452781e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "user_norm_train_matrix = train_matrix - train_matrix.mean(axis=1, keepdims=True)\n",
    "user_sim = cosine_similarity(user_norm_train_matrix, user_norm_train_matrix)\n",
    "\n",
    "print(user_sim.shape)\n",
    "print(user_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10845, 10845)\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00 -1.29374180e-03 ... -1.10092635e-03\n",
      "  -1.62468321e-03 -8.13712776e-04]\n",
      " [ 0.00000000e+00 -1.29374180e-03  1.00000000e+00 ... -2.09797158e-03\n",
      "   4.41126030e-02 -1.55064530e-03]\n",
      " ...\n",
      " [ 0.00000000e+00 -1.10092635e-03 -2.09797158e-03 ...  1.00000000e+00\n",
      "  -2.63463635e-03 -1.31954171e-03]\n",
      " [ 0.00000000e+00 -1.62468321e-03  4.41126030e-02 ... -2.63463635e-03\n",
      "   1.00000000e+00 -1.94730306e-03]\n",
      " [ 0.00000000e+00 -8.13712776e-04 -1.55064530e-03 ... -1.31954171e-03\n",
      "  -1.94730306e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "item_norm_train_matrix = train_matrix - train_matrix.mean(axis=0, keepdims=True)\n",
    "item_sim = cosine_similarity(item_norm_train_matrix.T, item_norm_train_matrix.T)\n",
    "\n",
    "print(item_sim.shape)\n",
    "print(item_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_cf_prediction(valid_users, valid_items, k, verbose=False):\n",
    "    \n",
    "    pred_ratings = []\n",
    "    for u, i in zip(valid_users, valid_items):\n",
    "        # get the candidate users that have boughted the target item i\n",
    "        candidate_user_index = train_matrix[:, i] > 0\n",
    "        if len(candidate_user_index) < 1:\n",
    "            print(f\"item {i} is not found in the training set\")\n",
    "            pred_ratings.append(train_matrix[u].mean())\n",
    "            continue\n",
    "\n",
    "        # compute the similarity of those users\n",
    "        this_user_sim = user_sim[u].copy()\n",
    "        this_user_sim[~candidate_user_index] = 0\n",
    "        candidate_sim = user_sim[u, candidate_user_index]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"predict rating for user_id {u} and item_id {i}\")\n",
    "            print(f\"candidate user index is a boolean array {candidate_user_index}\")\n",
    "            print(f\"there are {candidate_sim.shape[0]} candidate users\")\n",
    "\n",
    "        # select top k similar users with best absolute correlations\n",
    "        topk_sim_users = np.abs(this_user_sim).argsort()[-k:][::-1]\n",
    "        topk_sim = user_sim[u, topk_sim_users]\n",
    "        topk_ratings = user_norm_train_matrix[topk_sim_users, i]\n",
    "        if verbose:\n",
    "            print(f\"top {k} (if possible) similar users {topk_sim_users} are retrived\")\n",
    "            print(f\"\\t with similarity {topk_sim}\")\n",
    "            print(f\"\\t and ratings of {topk_ratings}\")\n",
    "\n",
    "        # make redictions by the user average and relative performance\n",
    "        user_ave = train_matrix[u].mean()\n",
    "        topk_ave = np.sum((topk_ratings * topk_sim))/(topk_sim.sum()+1e-6)\n",
    "        pred_rating = user_ave + topk_ave\n",
    "        pred_ratings.append(pred_rating)\n",
    "        if verbose:\n",
    "            print(f\"predict the rating {pred_rating:.4f} = user average {user_ave:.4f} + topk sim average {topk_ave:.4f}\")\n",
    "            print()\n",
    "    return np.asarray(pred_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict rating for user_id 4751 and item_id 9671\n",
      "candidate user index is a boolean array [False False False ... False False False]\n",
      "there are 4 candidate users\n",
      "top 3 (if possible) similar users [4842 3993 4435] are retrived\n",
      "\t with similarity [ 0.05599403  0.01080387 -0.00166243]\n",
      "\t and ratings of [4.9934532  2.93748271 4.99419087]\n",
      "predict the rating 4.6606 = user average 0.0082 + topk sim average 4.6523\n",
      "\n",
      "predict rating for user_id 2104 and item_id 3716\n",
      "candidate user index is a boolean array [False False False ... False False False]\n",
      "there are 24 candidate users\n",
      "top 3 (if possible) similar users [4295 2284 2123] are retrived\n",
      "\t with similarity [0.13758703 0.11640039 0.10527415]\n",
      "\t and ratings of [3.98939604 4.98819733 3.96864915]\n",
      "predict the rating 4.3139 = user average 0.0070 + topk sim average 4.3069\n",
      "\n",
      "predict rating for user_id 4207 and item_id 6856\n",
      "candidate user index is a boolean array [False False False ... False False False]\n",
      "there are 18 candidate users\n",
      "top 3 (if possible) similar users [1129  568  270] are retrived\n",
      "\t with similarity [0.06728525 0.06142159 0.05895832]\n",
      "\t and ratings of [2.95260489 3.7494698  3.98100507]\n",
      "predict the rating 3.5489 = user average 0.0124 + topk sim average 3.5365\n",
      "\n",
      "predict rating for user_id 3647 and item_id 8238\n",
      "candidate user index is a boolean array [False False False ... False False False]\n",
      "there are 43 candidate users\n",
      "top 3 (if possible) similar users [2805 4622 3980] are retrived\n",
      "\t with similarity [0.08721508 0.08713055 0.08296744]\n",
      "\t and ratings of [4.94900876 2.96071923 3.96108806]\n",
      "predict the rating 3.9787 = user average 0.0215 + topk sim average 3.9572\n",
      "\n",
      "predict rating for user_id 1 and item_id 124\n",
      "candidate user index is a boolean array [False False False ... False False False]\n",
      "there are 9 candidate users\n",
      "top 3 (if possible) similar users [3716 2627  520] are retrived\n",
      "\t with similarity [0.26009057 0.17103117 0.11467129]\n",
      "\t and ratings of [4.99511296 4.99621946 4.9945597 ]\n",
      "predict the rating 4.9977 = user average 0.0024 + topk sim average 4.9953\n",
      "\n",
      "[4.66055042 4.31392305 3.54893295 3.97866664 4.99773172] [5. 4. 5. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "pred_ratings = user_cf_prediction(valid_users[:5], valid_items[:5], 3, verbose=True)\n",
    "print(pred_ratings, valid_ratings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict rating for user_id 4751 and item_id 9671\n",
      "candidate user index is a boolean array [False False False ... False False False]\n",
      "there are 4 candidate users\n",
      "top 10 (if possible) similar users [4842 3993 4435  729 1637 1655 1657 1658 1659 1660] are retrived\n",
      "\t with similarity [ 0.05599403  0.01080387 -0.00166243 -0.00103704  0.13346756 -0.00096937\n",
      " -0.00110126 -0.00072386 -0.00103381 -0.00150919]\n",
      "\t and ratings of [ 4.99345320e+00  2.93748271e+00  4.99419087e+00  2.99778700e+00\n",
      " -8.11433840e-03 -2.12079299e-03 -2.85846012e-03 -1.19870908e-03\n",
      " -2.30520977e-03 -4.51821116e-03]\n",
      "predict the rating 1.5629 = user average 0.0082 + topk sim average 1.5547\n",
      "\n",
      "predict rating for user_id 2104 and item_id 3716\n",
      "candidate user index is a boolean array [False False False ... False False False]\n",
      "there are 24 candidate users\n",
      "top 10 (if possible) similar users [4295 2284 2123 3772 2731 1207  637 3978 1936 4046] are retrived\n",
      "\t with similarity [0.13758703 0.11640039 0.10527415 0.09980196 0.09785796 0.08675663\n",
      " 0.06496048 0.05378663 0.05309259 0.03158452]\n",
      "\t and ratings of [3.98939604 4.98819733 3.96864915 4.96864915 4.97307515 4.99105579\n",
      " 4.99575841 3.98865837 4.99492854 3.98367911]\n",
      "predict the rating 4.6026 = user average 0.0070 + topk sim average 4.5956\n",
      "\n",
      "predict rating for user_id 4207 and item_id 6856\n",
      "candidate user index is a boolean array [False False False ... False False False]\n",
      "there are 18 candidate users\n",
      "top 10 (if possible) similar users [1129  568  270  563 3451 1801 2287 3871 1987 2134] are retrived\n",
      "\t with similarity [ 0.06728525  0.06142159  0.05895832  0.05865402  0.03865835  0.03315654\n",
      "  0.03228049  0.0297765   0.02021371 -0.00371982]\n",
      "\t and ratings of [2.95260489 3.7494698  3.98100507 3.97353619 3.9010604  2.9494698\n",
      " 2.97676349 3.9790687  3.9725219  2.97952974]\n",
      "predict the rating 3.6151 = user average 0.0124 + topk sim average 3.6027\n",
      "\n",
      "predict rating for user_id 3647 and item_id 8238\n",
      "candidate user index is a boolean array [False False False ... False False False]\n",
      "there are 43 candidate users\n",
      "top 10 (if possible) similar users [2805 4622 3980  824 4271 2202 3588 2183 2532 3568] are retrived\n",
      "\t with similarity [0.08721508 0.08713055 0.08296744 0.06307023 0.06257575 0.05938007\n",
      " 0.0538715  0.05087465 0.05036522 0.049222  ]\n",
      "\t and ratings of [4.94900876 2.96071923 3.96108806 4.92881512 2.93923467 4.95085293\n",
      " 3.98782849 2.99575841 4.97501153 3.997787  ]\n",
      "predict the rating 4.0755 = user average 0.0215 + topk sim average 4.0540\n",
      "\n",
      "predict rating for user_id 1 and item_id 124\n",
      "candidate user index is a boolean array [False False False ... False False False]\n",
      "there are 9 candidate users\n",
      "top 10 (if possible) similar users [3716 2627  520 2814 2966 4924 3202 2094 3526 1656] are retrived\n",
      "\t with similarity [ 0.26009057  0.17103117  0.11467129  0.08348373  0.06270174  0.05947645\n",
      " -0.00123987 -0.00103039 -0.00079406 -0.00157848]\n",
      "\t and ratings of [ 4.99511296  4.99621946  4.9945597   2.98340249  3.98063624  4.98644537\n",
      "  3.9879207   3.99151683  3.99548179 -0.01724297]\n",
      "predict the rating 4.7016 = user average 0.0024 + topk sim average 4.6992\n",
      "\n",
      "[1.56291432 4.60259373 3.61513531 4.07545007 4.7016389 ] [5. 4. 5. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "pred_ratings = user_cf_prediction(valid_users[:5], valid_items[:5], 10, verbose=True)\n",
    "print(pred_ratings, valid_ratings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user CF with top-1 similar users, RMSE = 1.5069515049286584\n",
      "user CF with top-2 similar users, RMSE = 1.6429612322007046\n",
      "user CF with top-3 similar users, RMSE = 2.384089999944481\n",
      "user CF with top-4 similar users, RMSE = 4.3451446065057855\n",
      "user CF with top-5 similar users, RMSE = 4.330470484576127\n",
      "user CF with top-10 similar users, RMSE = 8.796787091753346\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 2, 3, 4, 5, 10]:\n",
    "    pred_ratings = user_cf_prediction(valid_users, valid_items, k)\n",
    "    score = rmse(pred_ratings, valid_ratings)\n",
    "    print(f\"user CF with top-{k} similar users, RMSE = {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_cf_prediction(valid_users, valid_items, k, verbose=False):\n",
    "    \n",
    "    pred_ratings = []\n",
    "    for u, i in zip(valid_users, valid_items):\n",
    "        candidate_item_index = train_matrix[u, :] > 0\n",
    "        if len(candidate_item_index) < 1:\n",
    "            print(f\"item {i} is not found in the training set\")\n",
    "            pred_ratings.append(train_matrix[:, i].mean())\n",
    "            continue\n",
    "\n",
    "        this_item_sim = item_sim[i].copy()\n",
    "        this_item_sim[~candidate_item_index] = 0\n",
    "        candidate_sim = item_sim[i, candidate_item_index]\n",
    "\n",
    "        topk_sim_items = np.abs(this_item_sim).argsort()[-k:][::-1]\n",
    "        topk_sim = item_sim[i, topk_sim_items]\n",
    "        topk_ratings = item_norm_train_matrix[u, topk_sim_items]\n",
    "            \n",
    "        item_ave = train_matrix[:,i].mean()\n",
    "        topk_ave = np.sum((topk_ratings * topk_sim))/(topk_sim.sum()+1e-6)\n",
    "        pred_rating = item_ave + topk_ave\n",
    "        pred_ratings.append(pred_rating)\n",
    "        if verbose:\n",
    "            print(f\"predict the rating {pred_rating:.4f} = user average {item_ave:.4f} + topk sim average {topk_ave:.4f}\")\n",
    "            print()\n",
    "    return np.asarray(pred_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user CF with top-1 similar users, RMSE = 1.5514636064968197\n",
      "user CF with top-2 similar users, RMSE = 1.3931533204696869\n",
      "user CF with top-3 similar users, RMSE = 1.3659986075499237\n",
      "user CF with top-4 similar users, RMSE = 2.0621300994117795\n",
      "user CF with top-5 similar users, RMSE = 1.3762175607962124\n",
      "user CF with top-10 similar users, RMSE = 1.6793899948915336\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 2, 3, 4, 5, 10]:\n",
    "    pred_ratings = item_cf_prediction(valid_users, valid_items, k)\n",
    "    score = rmse(pred_ratings, valid_ratings)\n",
    "    print(f\"user CF with top-{k} similar items, RMSE = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization (Extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4981, 4981) (4981,) (4981, 10845)\n"
     ]
    }
   ],
   "source": [
    "U, S, Vh = svd(train_matrix, full_matrices=False)\n",
    "print(U.shape, S.shape, Vh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4981, 10) (10,) (10, 10845)\n"
     ]
    }
   ],
   "source": [
    "U, S, Vh = svds(train_matrix, k=10)\n",
    "print(U.shape, S.shape, Vh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_prediction(valid_users, valid_items, k=10):\n",
    "    pred = []\n",
    "    U, S, Vh = svds(train_matrix, k)\n",
    "    for u, i in zip(valid_users, valid_items):\n",
    "        p = U[u,:] @ np.diag(S) @ Vh[:, i]\n",
    "        pred.append(p)\n",
    "    return np.asarray(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD with 5 singular values, RMSE = 3.920749421205831\n",
      "SVD with 10 singular values, RMSE = 3.893203252399172\n",
      "SVD with 50 singular values, RMSE = 3.867340713589129\n",
      "SVD with 100 singular values, RMSE = 3.8810160966842435\n"
     ]
    }
   ],
   "source": [
    "for k in [5, 10, 50, 100]:\n",
    "    pred_ratings = svd_prediction(valid_users, valid_items, k)\n",
    "    score = rmse(pred_ratings, valid_ratings)\n",
    "    print(f\"SVD with {k} singular values, RMSE = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ncf_model(n_users, n_items, embed_size, output_layer='dot'):\n",
    "    '''\n",
    "    params:\n",
    "        -n_users: number of user embedding vectors\n",
    "        -n_items: number of item embedding vectors\n",
    "        -embed_size: dimension of each embedding vector\n",
    "        -output_layer: which instantiation of NCF to use ('dot' or 'mlp')\n",
    "\n",
    "    return:\n",
    "        a keras Model object for the constructed ncf model \n",
    "    '''\n",
    "\n",
    "    # Get the users and items input\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name='item_input')\n",
    "\n",
    "    \n",
    "    # Get the embeddings of users and items\n",
    "    \n",
    "    user_emb = Embedding(output_dim=embed_size, input_dim=n_users, input_length=1)(user_input)\n",
    "    user_emb = Reshape((embed_size,))(user_emb)\n",
    "\n",
    "    item_emb = Embedding(output_dim=embed_size, input_dim=n_items, input_length=1)(item_input)\n",
    "    item_emb = Reshape((embed_size,))(item_emb)\n",
    "\n",
    "    if output_layer == 'dot':\n",
    "        # Compute the dot product of users' and items' embeddings as the model output\n",
    "        model_output = Dot(axes=1)([user_emb, item_emb])\n",
    "\n",
    "    elif output_layer == 'mlp':\n",
    "\n",
    "        # Concatenate the users' and items' embeddings as the input of MLP \n",
    "        mlp_input = Concatenate()([user_emb, item_emb])\n",
    "\n",
    "        # First fully-connected layer\n",
    "        dense_1 = Dense(512, activation='relu')(mlp_input)\n",
    "        dense_1_dp = Dropout(0.15)(dense_1)\n",
    "\n",
    "        # Second fully-connected layer\n",
    "        dense_2 = Dense(512, activation='relu')(dense_1_dp)\n",
    "        dense_2_dp = Dropout(0.15)(dense_2)\n",
    "\n",
    "        # Final fully-connected layer to compute model output\n",
    "        model_output = Dense(1)(dense_2_dp)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    model = Model(inputs=[user_input, item_input],\n",
    "                  outputs=model_output)\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case(embed_size=10, output_layer='dot', epochs=1):\n",
    "    model = build_ncf_model(n_users, n_items, embed_size=embed_size, output_layer=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    history = model.fit(x=[train_users, train_items], y=train_ratings, epochs=epochs, verbose=1, callbacks=[ModelCheckpoint('model.h5')])\n",
    "    y_pred = model.predict([train_users, train_items])\n",
    "    print(\"TRAIN RMSE: \", rmse(y_pred, train_ratings))\n",
    "    y_pred = model.predict([valid_users, valid_items])\n",
    "    print(\"VALID RMSE: \", rmse(y_pred, valid_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 2s 601us/step - loss: 16.1138\n",
      "TRAIN RMSE:  3.9317740612311214\n",
      "VALID RMSE:  3.9449278138017005\n"
     ]
    }
   ],
   "source": [
    "case(embed_size=10, output_layer='dot', epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 2s 620us/step - loss: 16.1137\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 2s 610us/step - loss: 14.3278\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 2s 605us/step - loss: 8.7734\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 2s 605us/step - loss: 4.8003\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 2s 606us/step - loss: 2.8133\n",
      "TRAIN RMSE:  1.389861713164762\n",
      "VALID RMSE:  1.6435122699091151\n"
     ]
    }
   ],
   "source": [
    "case(embed_size=10, output_layer='dot', epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 2s 593us/step - loss: 16.1121\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 2s 603us/step - loss: 14.2756\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 2s 599us/step - loss: 8.7601\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 2s 604us/step - loss: 4.8530\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 2s 599us/step - loss: 2.9010\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 2s 603us/step - loss: 1.9412\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 2s 644us/step - loss: 1.4669\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 2s 657us/step - loss: 1.2248\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 2s 613us/step - loss: 1.0834\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 2s 604us/step - loss: 0.9837\n",
      "TRAIN RMSE:  0.9381400280619244\n",
      "VALID RMSE:  1.304390113031172\n"
     ]
    }
   ],
   "source": [
    "case(embed_size=10, output_layer='dot', epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case(embed_size=10, output_layer='mlp', epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case(embed_size=10, output_layer='mlp', epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case(embed_size=10, output_layer='mlp', epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
